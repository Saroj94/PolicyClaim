{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment\n",
    "import re\n",
    "df1=pd.DataFrame({'Name':['380df#67as','4545er#78fg','345667qw#898rt']})\n",
    "l=df1['Name']\n",
    "box=[]\n",
    "for i in l:\n",
    "    x=i.split('#')\n",
    "    box.append(x)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##experiment: removing string from a list of string values and converting into data frame\n",
    "ls=['380df', '67as','4545er', '78fg']\n",
    "dx=[]\n",
    "for i in ls:\n",
    "    d=re.findall(r'\\d+',i)\n",
    "    dx.append(d)\n",
    "\n",
    "## wraping into the dataframe\n",
    "df=pd.DataFrame(dx, columns=['dx_column'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final[['rt','lft','sd']]=pd.DataFrame(list(map(lambda x: re.findall(r'\\d+',x), df_final['max_power'].to_list())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def FeatureExtract(data: pd.DataFrame, feat: str, RColName: str, LColName: str) -> pd.DataFrame:\n",
    "    # Split the 'feat' column into two parts: left and right based on '@'\n",
    "    dfd = list(map(lambda x: x.split('@'), data[feat]))\n",
    "    \n",
    "    # Assign split parts to two new columns in the original data\n",
    "    data[[RColName, LColName]] = pd.DataFrame(dfd, columns=[RColName, LColName], index=data.index)\n",
    "    \n",
    "    # Extract numeric parts from 'RColName' and 'LColName' using re.findall\n",
    "    data[RColName] = data[RColName].apply(lambda x: int(re.findall(r'\\d+', x)[0]))  # Extract first number\n",
    "    data[LColName] = data[LColName].apply(lambda x: int(re.findall(r'\\d+', x)[0]))  # Extract first number\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Example usage:\n",
    "df = pd.DataFrame({\n",
    "    'max_torque': ['60Nm@3500rpm', '70Nm@4000rpm'],\n",
    "    'other_column': [1, 2]\n",
    "})\n",
    "\n",
    "# Call the function\n",
    "df = FeatureExtract(df, 'max_torque', 'MaxRpm', 'MaxTor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Verison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Target': ['Yes', 'No', 'Yes', 'No', 'Yes']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "def FeatEncoder(data: pd.DataFrame, feature: str, encoder: str) -> pd.DataFrame:\n",
    "    if encoder == 'LabelEncoder':\n",
    "        le = LabelEncoder()\n",
    "        data[feature] = le.fit_transform(data[feature])\n",
    "    elif encoder == 'ohe':\n",
    "        ohe = OneHotEncoder(sparse_output=False, drop='first')  # drop='first' to avoid multicollinearity\n",
    "        encoded = ohe.fit_transform(data[[feature]])\n",
    "        encoded_df = pd.DataFrame(encoded, columns=ohe.get_feature_names_out([feature]), index=data.index)\n",
    "        data = pd.concat([data.drop(columns=[feature]), encoded_df], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "dfs = pd.DataFrame({\n",
    "    'Category': ['mango', 'apple', 'grapes', 'pineapple', 'lemon']\n",
    "})\n",
    "\n",
    "def FeatureEncode(data:pd.DataFrame, feature:str, encoder:str)->pd.DataFrame:\n",
    "    if encoder=='LabelEncoder':\n",
    "        le = LabelEncoder()\n",
    "        data[feature] = le.fit_transform(data[feature])\n",
    "        \n",
    "    elif encoder=='ohe':\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore',sparse_output=False).set_output(transform='pandas') # Use sparse_output=False for dense array output\n",
    "        encoded = ohe.fit_transform(data[[feature]])  # Pass as 2D array\n",
    "        \n",
    "        # Creating a DataFrame from the encoded data\n",
    "        encoded_df = pd.DataFrame(encoded, columns=ohe.get_feature_names_out([feature]))\n",
    "        \n",
    "        # Concatenating the new columns to the original DataFrame and dropping the original feature\n",
    "        data = pd.concat([data, encoded_df], axis=1)\n",
    "        data.drop(columns=[feature], inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.DataFrame({\n",
    "    'Category': ['mango', 'apple', 'grapes', 'pineapple', 'lemon']\n",
    "})\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureEncode(dfs,'Category','ohe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Version code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "data = {\n",
    "    'Color': ['Red', 'Blue', 'Green', 'Blue', 'Red'],\n",
    "    'Car_Brand': ['Honda', 'Toyota', 'Ford', 'Ford', 'Honda'],\n",
    "    'Education_Level': ['Bachelor', 'High School', 'PhD', 'Master', 'Bachelor'],\n",
    "    'Customer_Rating': ['Good', 'Poor', 'Excellent', 'Average', 'Good'],\n",
    "    'Size': ['Medium', 'Small', 'Large', 'Medium', 'Large'],\n",
    "    'Experience_Level': ['Mid', 'Junior', 'Senior', 'Mid', 'Junior']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def FeatureExtractor(data: pd.DataFrame, feature: str, encoder: str) -> pd.DataFrame:\n",
    "    if encoder == 'LabelEncoder':\n",
    "        le = LabelEncoder()\n",
    "        data[feature] = le.fit_transform(data[feature])\n",
    "    elif encoder == 'ohe':\n",
    "        ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "        encoded = ohe.fit_transform(data[[feature]])\n",
    "        encoded_df = pd.DataFrame(encoded, columns=ohe.get_feature_names_out([feature]), index=data.index)\n",
    "        data = pd.concat([data.drop(columns=[feature]), encoded_df], axis=1)\n",
    "    return data\n",
    "\n",
    "cat = ['Color', 'Car_Brand', 'Customer_Rating']\n",
    "\n",
    "dfs = df.copy()  # Make a copy of original DataFrame\n",
    "for col in cat:\n",
    "    dfs = FeatureExtractor(dfs, col, 'ohe') ##dfs(name) should be same everytime.\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##font\n",
    "plt.title(\"Fig: Claim Probability by Car Segment\", fontsize=12, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "1. Most policyholders are quite young, with very few older policyholders.\n",
    "2. Possible reasons for extreme right skewness:\n",
    "- The insurance product might be more popular among younger individuals.\n",
    "- Older individuals may have different financial strategies (e.g., self-insurance or different policy types).\n",
    "- Some policies may have an upper age limit, cutting off a large portion of older age groups.\n",
    "3. The longer a policy is active, the higher the probability of filing a claim at some point.\n",
    "\n",
    "## Impact/Inference:\n",
    "-\tYoung policyholders claim more: Possibly riskier behavior, such as reckless driving (for auto insurance) or health issues (for health insurance).\n",
    "- New cars are more expensive to repair, so even minor accident/dent/damage can lead to costly claims.\n",
    "- Longer Policy tenure has more driving years effectively more chances of encountering an accident, theft, or damage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Step 1: Create a contingency table\n",
    "contingency_table = pd.crosstab(df['model'], df['Claim_status'])\n",
    "\n",
    "# Step 2: Perform Chi-Square test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Step 3: Output results\n",
    "print(f\"Chi-Square Statistic: {chi2:.4f}\")\n",
    "print(f\"Degrees of Freedom  : {dof}\")\n",
    "print(f\"p-value             : {p:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Group the 'vehicle_age' based on the 'Claim_status' categories (0 and 1)\n",
    "group_0 = df[df['Claim_status'] == 0]['vehicle_age']  # Group for Claim_status 0\n",
    "group_1 = df[df['Claim_status'] == 1]['vehicle_age']  # Group for Claim_status 1\n",
    "\n",
    "# Perform One-Way ANOVA test\n",
    "f_stat, p_value = stats.f_oneway(group_0, group_1)\n",
    "\n",
    "# Output the results\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Imbalance data\n",
    "<b>Oversampling:</b> Minority class has been oversampled using SMOTE(Synthetic Minority Over-Sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Performing oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "##Oversampled the training dataset\n",
    "smote_sample=SMOTE(random_state=42)\n",
    "X_sampled,y_sampled=smote_sample.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##checking categorical feature vs target feature\n",
    "# from scipy.stats import chi2_contingency\n",
    "\n",
    "# # Step 1: Create a contingency table\n",
    "# plist=[]\n",
    "# nplist=[]\n",
    "# for col in cat_feature:    \n",
    "#     contingency_table = pd.crosstab(Xdata[col], Xdata['claim_status'])\n",
    "\n",
    "#     # Step 2: Perform Chi-Square test\n",
    "#     chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "#     # Step 3: Output results\n",
    "#     print(col)\n",
    "#     print(f\"Chi-Square Statistic: {chi2:.4f}\")\n",
    "#     print(f\"Degrees of Freedom  : {dof}\")\n",
    "#     print(f\"p-value             : {p:.6f}\")\n",
    "#     if p<0.05:\n",
    "#         plist.append(col)\n",
    "#     else:\n",
    "#         nplist.append(col)\n",
    "#     print('=='*30,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Feature selection for numerical feature\n",
    "# import scipy.stats as stats\n",
    "\n",
    "# # Group the 'vehicle_age' based on the 'Claim_status' categories (0 and 1)\n",
    "# group_0 = Xdata[Xdata['claim_status'] == 0]['vehicle_age']  # Group for Claim_status 0\n",
    "# group_1 = Xdata[Xdata['claim_status'] == 1]['vehicle_age']  # Group for Claim_status 1\n",
    "\n",
    "# # Perform One-Way ANOVA test\n",
    "# f_stat, p_value = stats.f_oneway(group_0, group_1)\n",
    "\n",
    "# # Output the results\n",
    "# print(f\"F-statistic: {f_stat:.4f}\")\n",
    "# print(f\"P-value: {p_value:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled, y_train_resampled = resample(X_train, y_train, replace=True, \n",
    "                                                n_samples=len(y_train[y_train == 0]), \n",
    "                                                random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
